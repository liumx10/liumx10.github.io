<!DOCTYPE html><html lang="en"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>cc-4 &quot;Non-locking concurrency control&quot; | Dreamworks</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/3.0.3/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.5.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/2.2.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">cc-4 &quot;Non-locking concurrency control&quot;</h1><a id="logo" href="/.">Dreamworks</a><p class="description">Homepage</p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> Home</i></a><a href="/archives/"><i class="fa fa-archive"> Archive</i></a><a href="/about/"><i class="fa fa-user"> About</i></a><a href="/atom.xml"><i class="fa fa-rss"> RSS</i></a></div></div><div id="layout" class="pure-g"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">cc-4 &quot;Non-locking concurrency control&quot;</h1><div class="post-meta">Apr 27, 2016<script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> Hits</span></span></div><div class="post-content"><h2 id="4-1-Introduction"><a href="#4-1-Introduction" class="headerlink" title="4.1 Introduction"></a>4.1 Introduction</h2><p>之前说的2PL是一种实现Recoverable和Serializable的方法，这里介绍两种新的方法，时间戳(TO)和序列图检测(SGT)。和2pl一样，这两种方法也有激进/保守、单机/分布式的区别。</p>
<h2 id="4-2-TO"><a href="#4-2-TO" class="headerlink" title="4.2 TO"></a>4.2 TO</h2><p>方法描述起来很简单。每一个transaction，都是被赋予一个独一无二的timestamp。如果两个操作冲突了，调度器就会保证时间戳更早的transaction对应的操作先执行</p>
<blockquote>
<p>如果$p_i[x]，q_j[x]$冲突，当且仅当$ts(T_i) &lt; ts(T_j)$，Data Manager先执行p。</p>
</blockquote>
<p>满足上述条件的执行一定是可序列化的执行。证明也很简单，就是两个操作如果冲突，一定会按照时间戳的顺序执行。这样SG中就不会有环了。</p>
<h3 id="基本的时间戳算法"><a href="#基本的时间戳算法" class="headerlink" title="基本的时间戳算法"></a>基本的时间戳算法</h3><p>基本的TO算法，是一个激进的算法。TM收到任何操作，都立刻转发给DM；如果发现有冲突操作来得太迟，即$p_i[x]$与$q_j[x]$冲突，且$ts(T_i) &lt; ts(T_j)$，q先执行。所以只能abort掉$T_i$。</p>
<p>abort掉之后，需要重发，重发的transaction必须有一个新的时间戳，而且这个时间戳必须造成自己abort的那个要晚，不然会出现一直abort的现象。</p>
<p>具体实现方法是：对于每个object，有一个 queue，作为被pending的任务；一个w-in-transits，一个r-in-transits，表明正在被下层DM执行的读写任务数量（当然，w-in-transits只能是0或者1，这个有点像读写锁）。还有一个max-w-schedued / max-r-schedued，表面已经完成的最大的读写的transaction的TO。</p>
<p>那么，在一个任务到了TM的时候，比如是read，需要判断max-w-schedued 是否比自己大，比自己大直接丢掉；如果比自己小，进一步判断，w-in-transits是否为0，是0可以直接操作，不是0需要等一会，即进入到queue里面。</p>
<h3 id="strict-TO"><a href="#strict-TO" class="headerlink" title="strict TO"></a>strict TO</h3><p>basic TO 只能保证serializability，不能保证recoverability.这个很好理解，因为一个transaction完全可以读另外一个事务的值，然后先commit了，basic TO对此并没有限制。</p>
<p>实现的目标很简单：就是让一个write所在的transaction，在abort/commit之前，别人不能读或者写。因此实现起来也比较简单，在basic TO中，当一个写完成的时候，立刻更新 w-in-transits （减1），现在改为 abort/commit 之后在更新，即写操作会阻塞之后所有的读操作或者写操作。</p>
<p>这个看起来更像是读写锁了，但是跟2PL还是有点不太一样，那就是对读。对于（strict）2PL，如果读一旦上锁，那么直到该transaction结束，才会释放这个锁；但是对于strict TO 不一样，读结束之后可以立刻进行下一个写。</p>
<h3 id="timestamp-management"><a href="#timestamp-management" class="headerlink" title="timestamp management"></a>timestamp management</h3><p>从上面介绍的方法来看，TO一个比较突出的问题就是太占空间。一个object需要有好几个参数。所以最后很有可能timestamp比数据库本身还大。</p>
<p>实际上，对于一个TM来说，收到的transaction请求往往是一个时间窗口内的，不会差距太大。因此可以设置一个$ts_{min}$，所有低于这个timestamp的都可以删了，然后默认每个object上的最小值都是这个值。如果真的有transaction低于这个值，直接杀掉。这样误杀率也会很低。</p>
<h3 id="distributed-TO"><a href="#distributed-TO" class="headerlink" title="distributed TO"></a>distributed TO</h3><p>Distributed TO 非常简单，因为每个机器只用关心自己存储的object的timestamp信息，彼此之间没有任何交互，只需要有一个中心化的timestamp生成器就可以了。这个跟2PL不一样，2PL还需要全局交互检查死锁。</p>
<h3 id="conservative-TO"><a href="#conservative-TO" class="headerlink" title="conservative TO"></a>conservative TO</h3><p>保守策略只有一点不同，就是在收到请求之后等一小会，等一会带着更小的timestamp的请求过来，这样会减少abort的几率。此处又有一个trade-off。</p>
<p>还有一种极端保守的策略，固定好Transaction Manager的数量，保证在queue里面有来自所有TM的operation，且给他们排好序。这样确保每次执行的都是ts最小的，没有任何transaction会被abort。如果一个TM没有任何操作可做，可以发NULL。</p>
<p>但其实这种极端保守等价于串行执行了。没有任何意义。有一种改进的策略，是指定 transaction class，每个class 有一个readset和一个writeset，每个transaction一定属于一个（或多个）transaction class，即他的readset/writeset是该transaction class的子集。因此，只有一个class内的会有冲突。于是上文说的，queue只用保证一个会有冲突的transaction class对应的TM都有操作（一个transaction class对应一个TM）即可。这样可以提高并行度，但需要知道所有transaction的readset、writeset。</p>
<h2 id="Serialization-Graph-Testing"><a href="#Serialization-Graph-Testing" class="headerlink" title="Serialization Graph Testing"></a>Serialization Graph Testing</h2><h3 id="Basic-SGT"><a href="#Basic-SGT" class="headerlink" title="Basic SGT"></a>Basic SGT</h3><p>这个方法是从本质上解决非串行化的问题，可以说是一个比较紧的界。具体来说，每当有新的操作产生，（可能）会有新的conflict，即不同transaction之间的依赖关系产生。也就是说，这个图会不断地增长。如果一旦发现环，就说明已经不是serializable了，需要终止掉当前的这个事务，使得依赖图依然是一个无环图。</p>
<p>实现起来比较麻烦，首先需要维护每个transaction的readset和writeset；其次需要加入新操作之后能够迅速地找到conflict（书中没有说怎么找，个人猜测每个 object 本身有一个transaction list）</p>
<p>还有一个难点是如何把确定没有用的transaction从图中移走。即使一个transaction已经commit了，也不能从图中移走；原因是因为他依然可能构成环。事实上，一个transaction commit之后，不会再有新的入边（它不会读新的东西了，因此也不会再去依赖别人），如果它完全没有入边，那么可以确定永远不会构成环。所以只把没有入边的节点给剔除掉。</p>
<h3 id="conservative-SGT"><a href="#conservative-SGT" class="headerlink" title="conservative SGT"></a>conservative SGT</h3><p>同样的，还有一种保守的SGT方法，即让transaction延迟一下，等到条件达到才进行操作。这里也需要transaction 预先知道自己的readset和writeset。每当一个transaction开始的时候，就往 SSG里面添加若干条边。因为每次都加的是入边，所以永远不会有环。但是需要保证的是，operations执行的顺序也是按照SSG里面的顺序来的。</p>
<p>具体操作是，当$T_i$的一个操作p排在queue的头部时，需要等</p>
<ol>
<li>所有发送给DM的与p冲突的操作，已经完成（ack）</li>
<li>所以在SSG中，在$T_i$的直接前继节点，所有与p冲突的操作都已经完成。（或者没有与p冲突的操作）</li>
</ol>
<h3 id="Recoverability"><a href="#Recoverability" class="headerlink" title="Recoverability"></a>Recoverability</h3><p>但是同样的，SGT和conservative SGT都不保证Recoverability。因为并不能保证后面的transaction后commit。也可以用和strict TO的方法，使得transaction可以达到strict：等到transaction commit/abort的时候，才把对应的 write 置为 ack，即把上面第一个条件阻塞住。</p>
<p>也可以用来实现更若的recoverability。比如为了实现ADA，（只读已经commit的），需要区分read/write。跟上面的区别在于，write不会阻塞write。有一个方法是，对于任何一个$r_i[x]$， 在SSG中所有 w-scheduled 中含有x的transaction，会形成一条链，那么在$T_i$最前面的一个为 $T_j$。 只有 $T_j$ commit之后， $r_i$ 才会被执行。</p>
<p>如果仅仅为了实现Recoverable，（冲突操作的顺序和commit的顺序一样），跟上面的区别在于，只需要堵塞住 $T_i$ 的commit即可。当然，因为这个不能避免 cascading abort；当一个transaction abort的时候，所有依赖它的也会被abort掉。</p>
<h3 id="Distributed-SGT"><a href="#Distributed-SGT" class="headerlink" title="Distributed SGT"></a>Distributed SGT</h3><p>因为SSG分布在不同机器上，所有检查 cycle非常麻烦，需要多个图合并；同时，跟死锁不一样，死锁的时候大家都会等着；而SGT中，如果没发现cycle，会立刻往下执行，就导致错误。所以每有一个新的transaction，需要同步一次SSG，这个开销非常大。所以SSG不太适合在分布式系统中。（当然，系统规模比较小，可以考虑用一个机器单独处理SSG）</p>
<h3 id="Space-efficient-SGT"><a href="#Space-efficient-SGT" class="headerlink" title="Space-efficient SGT"></a>Space-efficient SGT</h3><p>跳过。</p>
<h2 id="certifier-乐观控制"><a href="#certifier-乐观控制" class="headerlink" title="certifier (乐观控制)"></a>certifier (乐观控制)</h2><p>之前说的，所有的操作到达了Scheduler的时候，都会被检查，执行、回滚或者delay。另外一种方式，是直接操作，最后commit的时候再检查。2PL、TO、SGT都有对应的乐观的版本。</p>
<h3 id="2PL-certifier"><a href="#2PL-certifier" class="headerlink" title="2PL certifier"></a>2PL certifier</h3><p>每次收到read/write 请求，直接执行；收到commit请求，判断当前transaction 是否跟 任何 active的transaction conflict；如果有就abort。<br>需要的数据结构有：transaction nodes；每个transaction 有readset[$T_i$]和writeset[$T_i$]。证明：</p>
<ol>
<li>假设H为任意一个上述协议产生的history，$T_j \rightarrow T_i$ 是SG(H)中一条边，因此会有两个操作 $p_i[x]$ 和 $q_j[x]$ 为冲突操作，且 $p_j[x] &lt; p_i[x]$.</li>
<li>假设$T_i$是先调用 commit (certifier)的，那么此时, $p_j[x]$肯定是被执行完的，否则不会$p_j[x]$ &lt; $p_i[x]$。那么在 $T_i$ 进行检查的时候，肯定会被abort掉。因此，$T_j$ 先被 certified。</li>
<li>如果SG(H)中有一个环，$T_j, T_i, …, T_k, T_j$，$T_j$ 在自己之前被certified，显然不可能。</li>
</ol>
<p>为什么称之为 2PL 呢（实际上并没有用到任何lock）？因为每次一个operation被执行时，相当于加上了一把锁；任何两个冲突的事务，先提交的会被abort。</p>
<p>为了保证recoverability，需要额外加一个，如果一个transaction $T_i$ 被 abort掉了，那么读它的transaction $T_j$ 也必须要abort。但是怎么做呢：选取 readset[$T_j$] 和 writeset[$T_i$] 交集不为空。但这样会误杀，因为可能 $T_i$执行在后。但是上述的方法没法判断两个操作的先后顺序关系。因此只能误杀了。</p>
<p>（如此看来，如果不引入延迟，certifier没办法达到 ADA?)</p>
<p>最后从性能分析上来说，2PL certifier比原生的2PL性能要差；因为两个冲突的事务，会执行到结束之后才发现要abort，这样会浪费执行的资源。因此，当conflict程度大的时候，乐观控制性能总是会下降地特别快。</p>
<h3 id="SGT-certifier"><a href="#SGT-certifier" class="headerlink" title="SGT certifier"></a>SGT certifier</h3><p>SGT本质上和 certifier很像；所以改起来很容易。在Scheduler收到请求的时候，直接发送到DM。只在收到commit请求的时候，才会去判断是否有环；如果有环，则需要abort掉当前的事务。Recoverability是一样的，当一个事务被abort掉，所有(可能)依赖于它的事务。</p>
<h3 id="TO-certifier"><a href="#TO-certifier" class="headerlink" title="TO certifier"></a>TO certifier</h3><p>和 Basic TO没啥区别，就是在commit的时候检查有没有按照 timestamp order 执行的；没有的话abort掉自己。所以这里用乐观控制没啥用。性能反而低了，因为有大量的浪费。</p>
<h3 id="distributed-certifier"><a href="#distributed-certifier" class="headerlink" title="distributed certifier"></a>distributed certifier</h3><p>和之前distributed SGT一样，local的certifier不准，必须要有全局的certifier。</p>
<h2 id="组合的策略"><a href="#组合的策略" class="headerlink" title="组合的策略"></a>组合的策略</h2><p>之前讨论的策略主要是三种，2PL，TO，SGT，悲观和乐观的都有。这一节主要讨论的是如何将多种方法组合起来使用。回到冲突本身，有rw-conflict和ww-conflict，如果对这两种冲突使用同一种策略叫 pure scheduler，如果使用不同策略叫 mixed scheduler。之前我们讨论的都是 pure。</p>
<p>rw serialization graph (rw SG) 也可以分成两个，每个图里面的边，都是由某一种冲突构成的（rw-conflict/ww-conflict)。记作 $SG_{rw}(H)$ 或者 $SG_{ww}(H)$。只要两个图的并集，是一个无环图，那么history也是SR的。</p>
<h3 id="Thomas’-Write-Rule-TWR"><a href="#Thomas’-Write-Rule-TWR" class="headerlink" title="Thomas’ Write Rule (TWR)"></a>Thomas’ Write Rule (TWR)</h3><p>在TO中，如果收到了一个比较早的写，$w_i[x]$，但是之前已经执行过 $w_j[x]$, 且 i &lt; j。按照Basic TO，这个transaction应该回滚的。但是如果我们只关心ww-conflict，其实这里没必要回滚。因为我们可以“假装” $w_i[x]$ 已经执行过了，效果是一样的（会被 $w_j[x]$覆盖）。这个现象称之为 TWR。再加一个rw synchronizer，就可以完美处理所有的冲突了。下面会介绍两种基于TWR的设计。</p>
<h3 id="Pure-integrated-scheduler"><a href="#Pure-integrated-scheduler" class="headerlink" title="Pure integrated scheduler"></a>Pure integrated scheduler</h3><p>就是Basic TO (rw-conflict) + TWR (ww-conflict)。Basic TO只关心读写冲突。所以会对每个 object，记所有的tx的timestamp。</p>
<h3 id="A-mixed-integrated-scheduler"><a href="#A-mixed-integrated-scheduler" class="headerlink" title="A mixed integrated scheduler"></a>A mixed integrated scheduler</h3><p>这里是 strict 2PL + TWR。需要保证下面的条件；</p>
<ol>
<li>如果在 $SG_{rw}(H)$ 中，$T_i \rightarrow T_j$, 则 ts($T_i$) &lt; ts($T_j$)。</li>
</ol>
<p>先看下，如果$SG_{rw}(H)$满足这个条件，同时又因为 $SG_{ww}(H)$ 中，也一定满足这个条件，所以两个图的并集也一定是无环的（证明和TO的证明是一样的）。所以就能保证它是SR的。后面就展开如何保证这个条件。</p>
<p>进一步推导，如果$SG_{rw}(H)$中 $T_i &lt; T_j$。说明 $T_i$先拿到锁，又因为是strict 2PL，直到commit才会释放锁。所以$T_i$会先commit。</p>
<ol>
<li>如果 $T_i$ 先发出commit请求，则 ts($T_i$) &lt; ts($T_j)。<br>如果2满足，则1一定满足。（三段论）。</li>
</ol>
<p>实现中，如果按照basic TO，先给每个transaction赋一个ts，则不能保证条件2，因为谁先拿到锁谁会先试图commit。即使Scheduler上再套一层，按照顺序一个一个接受commit，也不行，因为只有ts小的有可能会被大的锁阻塞住（类似死锁）。所以只能说在commit的时候才给每个transaction赋ts，同时阻塞所有的写（因为只有ts TWR才能工作），假装已经完成，但实际上并没有操作。</p>
<p>这种设计一是挺反直觉；第二个问题在于，read没法读自己的。解决方法是：如果在read请求，试图拿读锁的时候，发现写锁已经被自己拿住了，那么直接读自己的即可；否则的话，要么被其他人的写锁阻塞住，要么成功拿到读锁，直接执行读就可以了。不可能存在在ts比自己小的写，且这个被Scheduler阻塞住，因为这些写的ts肯定比自己大。</p>
</div><script type="text/javascript" src="/js/share.js?v=0.0.0" async></script><a data-url="http://liumx10.github.io/2016/04/27/cc-4-1/" data-id="cjt5ic12v000rz57xe7jfctnq" class="article-share-link">Share</a><div class="tags"><a href="/tags/concurrency-control/">concurrency control</a></div><div class="post-nav"><a href="/2016/05/16/虚拟文件系统/" class="pre">虚拟文件系统</a><a href="/2016/04/27/cc-3-3/" class="next">cc-3-3</a></div></div></div></div><div class="pure-u-1-4"><div id="sidebar"><div class="widget"><form action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank" class="search-form"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="http://liumx10.github.io"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> Categories</i></div></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> Tags</i></div><div class="tagcloud"><a href="/tags/distributed-system/" style="font-size: 15px;">distributed system</a> <a href="/tags/concurrency-control/" style="font-size: 15px;">concurrency control</a> <a href="/tags/computer-structure/" style="font-size: 15px;">computer structure</a> <a href="/tags/big-data/" style="font-size: 15px;">big data</a> <a href="/tags/课程笔记/" style="font-size: 15px;">课程笔记</a> <a href="/tags/NVML/" style="font-size: 15px;">NVML</a> <a href="/tags/Transactional-Memory/" style="font-size: 15px;">Transactional Memory</a> <a href="/tags/OLTP/" style="font-size: 15px;">OLTP</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> Recent</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2019/03/07/cc-5-1/">cc-5-1</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/08/20/Speedup-RW-conflict-tracking-in-PostgreSQL/">Speedup RW-conflict tracking in PostgreSQL</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/08/29/pmemlib-1/">NVM library 源码分析(1) libpmem</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/08/25/core/">core-chip-processor-socket等的区别</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/07/06/tsx/">tsx</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/06/21/BigTable/">BigTable</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/06/21/dynamo/">dynamo</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/06/21/spark/">spark</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/06/21/dryad/">dryad</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/06/19/MapReduce/">MapReduce</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> Blogroll</i></div><ul></ul><a href="http://madsys.cs.tsinghua.edu.cn/" title="madsys" target="_blank">madsys</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">© <a href="/." rel="nofollow">Dreamworks.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a id="rocket" href="#top" class="show"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.pack.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="/css/jquery.fancybox.css?v=0.0.0"><script type="text/x-mathjax-config">MathJax.Hub.Config({"HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"], linebreaks: { automatic:true }, EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50) },
      tex2jax: { inlineMath: [ ["$", "$"], ["\\(","\\)"] ], processEscapes: true, ignoreClass: "tex2jax_ignore|dno",skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']},
      TeX: {  noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } }, Macros: { href: "{}" } },
      messageStyle: "none"
  });
</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
</script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>